{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from xml.etree import ElementTree as ET\n",
    "from xml.dom import minidom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"start-maximized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=chrome_options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECIPES_INFOR_DIR = './data/recipes'\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "os.makedirs(RECIPES_INFOR_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_URL = 'https://pinchofyum.com/recipes'\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=chrome_options\n",
    ")\n",
    "driver.get(MAIN_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://pinchofyum.com/recipes/all'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "MAIN_URL = 'https://pinchofyum.com/recipes'\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=chrome_options\n",
    ")\n",
    "driver.get(MAIN_URL)\n",
    "\n",
    "response = requests.get(MAIN_URL)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "sections = soup.find_all('section', 'py-8 px-4 mx-auto md:max-w-5xl recipe-lists')\n",
    "recipe_types: dict[str, dict] = {}\n",
    "data = ET.Element('data')\n",
    "for section in sections:\n",
    "    recipe_type: str = section.find('h2').text\n",
    "    recipe_type_children = section.find_all('a')\n",
    "    recipe_types[recipe_type] = {}\n",
    "    recipe_type_tag = ET.SubElement(data, 'parenttype', {'name': recipe_type})\n",
    "\n",
    "    for recipe_type_child in recipe_type_children:\n",
    "        recipe_types[recipe_type][recipe_type_child.text] = recipe_type_child['href']\n",
    "        recipe_type_child_tag = ET.SubElement(recipe_type_tag, 'childtype', name=recipe_type_child.text)\n",
    "\n",
    "def prettify_xml(elem):\n",
    "    rough_string = ET.tostring(elem, encoding=\"unicode\")\n",
    "    parsed = minidom.parseString(rough_string)\n",
    "    return parsed.toprettyxml(indent=\"\\t\")\n",
    "\n",
    "FILE_PATH = './data/recipe_types/recipe_types.xml'\n",
    "\n",
    "with open(FILE_PATH, 'w', encoding='utf-8') as f:\n",
    "    f.write(prettify_xml(data))\n",
    "recipe_types['Popular Categories'].pop('All Recipes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [02:23<00:00, 11.04s/it]\n",
      "100%|██████████| 7/7 [00:58<00:00,  8.30s/it]]\n",
      "100%|██████████| 9/9 [01:37<00:00, 10.82s/it] \n",
      "100%|██████████| 6/6 [00:51<00:00,  8.64s/it]\n",
      "100%|██████████| 4/4 [00:37<00:00,  9.33s/it]\n",
      "100%|██████████| 5/5 [00:37<00:00,  7.54s/it]\n",
      "100%|██████████| 29/29 [04:21<00:00,  9.02s/it]\n",
      "100%|██████████| 6/6 [00:34<00:00,  5.70s/it]]\n",
      "100%|██████████| 8/8 [12:01<00:00, 90.21s/it] \n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "# root cua file xml\n",
    "data = ET.Element('data')\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "for recipe_type_name, child_types in tqdm.tqdm(recipe_types.items()):\n",
    "\n",
    "    recipe = ET.Element('recipe')\n",
    "\n",
    "    # Lay noi dung parent type recipe\n",
    "    parenttype      = ET.SubElement(recipe, 'parenttype')\n",
    "    parenttype.text = recipe_type_name\n",
    "\n",
    "    recipe_type_tag = ET.SubElement(data, 'parenttype', {'name': recipe_type_name})\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    for child_type_name, link in tqdm.tqdm(child_types.items()):\n",
    "\n",
    "        # Lay noi dung child type name\n",
    "        childtype      = ET.SubElement(parenttype, 'childtype')\n",
    "        childtype.text = child_type_name\n",
    "\n",
    "        recipe_type_child_tag = ET.SubElement(recipe_type_tag, 'childtype', name=child_type_name)\n",
    "\n",
    "        # Chuyen toi link khac\n",
    "        driver.get(link)\n",
    "\n",
    "        # Tim header p\n",
    "        recipe_type_child_tag.text = driver.find_element(By.XPATH, '//div[@class=\"cat-desc col-span-8 px-8 pt-4 md:pt-0 pb-12\"]/p').text\n",
    "\n",
    "\n",
    "FILE_PATH = './data/recipe_types/recipe_types_2.xml'\n",
    "\n",
    "def prettify_xml(elem):\n",
    "    rough_string = ET.tostring(elem, encoding=\"unicode\")\n",
    "    parsed = minidom.parseString(rough_string)\n",
    "    return parsed.toprettyxml(indent=\"\\t\")\n",
    "\n",
    "with open(FILE_PATH, 'w', encoding='utf-8') as f:\n",
    "    f.write(prettify_xml(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_xml_file(data, file_path: str):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(prettify_xml(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "# actions = ActionChains(driver)\n",
    "\n",
    "# root cua cac file xml\n",
    "specified_types = ET.Element('specifiedtype')\n",
    "count = 0\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "for recipe_type_name, child_types in tqdm.tqdm(recipe_types.items()):\n",
    "\n",
    "    recipe = ET.Element('recipe')\n",
    "\n",
    "    # Lay noi dung parent type recipe\n",
    "    parenttype      = ET.SubElement(recipe, 'parenttype')\n",
    "    parenttype.text = recipe_type_name\n",
    "\n",
    "    specified_parenttype = ET.SubElement(specified_types, 'parenttpye', {'name': recipe_type_name})\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    for child_type_name, link in tqdm.tqdm(child_types.items()):\n",
    "\n",
    "        # Lay noi dung child type name\n",
    "        childtype      = ET.SubElement(parenttype, 'childtype')\n",
    "        childtype.text = child_type_name\n",
    "\n",
    "        specified_childtype = ET.SubElement(specified_parenttype, 'childtype', {'name': child_type_name})\n",
    "\n",
    "        # Chuyen toi link khac\n",
    "        driver.get(link)\n",
    "\n",
    "        # Tim cac <section> chua specified type\n",
    "        sections = driver.find_elements(By.XPATH, '//section[@class=\"md:max-w-6xl mx-auto px-4 py-12 border-b\"]')\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        sections_dict = {}\n",
    "        for section in tqdm.tqdm(sections):\n",
    "\n",
    "            specified_type_element = ET.SubElement(specified_childtype, 'specifiedtype')\n",
    "            \n",
    "            # Lay cac <header> trong section\n",
    "            section_header = section.find_element(By.TAG_NAME, 'header')\n",
    "            \n",
    "            # Lay cac <h2> trong section\n",
    "            try:\n",
    "                section_header_h2              = section_header.find_element(By.TAG_NAME, 'h2')\n",
    "                section_header_h2_element      = ET.SubElement(specified_type_element, 'title')\n",
    "                section_header_h2_element.text = section_header_h2.text\n",
    "            except NoSuchElementException as ex:\n",
    "                print(\"Exception:\", ex.msg)\n",
    "\n",
    "            # Lay cac <p> trong section header\n",
    "            try:\n",
    "                section_header_p              = section_header.find_element(By.TAG_NAME, 'p')\n",
    "                section_header_p_element      = ET.SubElement(specified_type_element, 'description')\n",
    "                section_header_p_element.text = section_header_p.text\n",
    "            except NoSuchElementException as ex:\n",
    "                print(\"Exception:\", ex.msg)\n",
    "\n",
    "            # Lay cac ten cua cac mon an co ten loai\n",
    "            specified_type_recipe_name_element = ET.SubElement(specified_type_element, 'recipes')\n",
    "            try:\n",
    "                div_element = section.find_element(By.XPATH, './/div[@class=\"flickity-viewport\"]')\n",
    "                div_element_soup = BeautifulSoup(div_element.get_attribute(\"innerHTML\"), \"html.parser\")\n",
    "                h3_elements = div_element_soup.find_all('h3')\n",
    "                sections_dict[section_header_h2.text] = set()\n",
    "                for h3_element in h3_elements:\n",
    "                    sections_dict[section_header_h2.text].add(h3_element.text)\n",
    "                    text_tag = ET.SubElement(specified_type_recipe_name_element, 'recipe', {'name': h3_element.text})\n",
    "\n",
    "            except NoSuchElementException as ex:\n",
    "                print(\"Exception:\", ex.msg)\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # Xu ly trang dau tien\n",
    "        articles = driver.find_elements(By.XPATH, '//div[@class=\"grid grid-cols-12 gap-4\"]/article')\n",
    "        recipe_root = ET.Element('recipe')\n",
    "        for article in tqdm.tqdm(articles)  :\n",
    "\n",
    "            parenttype_tag = ET.SubElement(recipe_root, 'parrenttype', {'name': recipe_type_name}) # Them loai parent\n",
    "            childtype_tag = ET.SubElement(recipe_root, 'childtype', {'name': child_type_name}) # them loai child\n",
    "\n",
    "            # Lay tat ca anh kich thuoc khac nhau\n",
    "            recipe_repr_img_urls = article.find_element(By.TAG_NAME, 'img').get_attribute('srcset')\n",
    "            recipe_repr_img_urls = [recipe_repr_img_url.split()[0] for recipe_repr_img_url in recipe_repr_img_urls.split(\", \")]\n",
    "            img_tag = ET.SubElement(recipe_root, 'images')\n",
    "            [ET.SubElement(img_tag, 'image', {'url': url}) for url in recipe_repr_img_urls]\n",
    "\n",
    "            # Lay link\n",
    "            recipe_link = article.find_element(By.TAG_NAME, 'a')\n",
    "\n",
    "            # Mo tab moi\n",
    "            driver.execute_script(\"window.open(arguments[0].href, '_blank');\", recipe_link)\n",
    "            driver.switch_to.window(driver.window_handles[1])\n",
    "\n",
    "            # Lay specified type neu co\n",
    "            article_tag = driver.find_element(By.TAG_NAME, 'article')\n",
    "            article_header = article_tag.find_element(By.XPATH, './/header/h1')\n",
    "            for childtype in sections_dict.keys():\n",
    "                if article_header.text in sections_dict[childtype]:\n",
    "                    ET.SubElement(recipe_root, 'specifiedtype', {\"name\": childtype})\n",
    "                    break\n",
    "            else:\n",
    "                ET.SubElement(recipe_root, 'specifiedtype', {\"name\": \"\"})\n",
    "\n",
    "            # Lay ten recipe\n",
    "            ET.SubElement(recipe_root, 'title', {\"name\": article_header.text})\n",
    "\n",
    "            # Lay reviews va sao\n",
    "            reviews_and_avgstars_tag = article_tag.find_elements(By.XPATH, './/div[@class=\"text-xxs text-gray-700 tracking-wider md:tracking-extra-widest uppercase font-arvo\"]/span')\n",
    "            ET.SubElement(recipe_root, \"reviews\", {\"quantity\": reviews_and_avgstars_tag[0].text.split()[0]}) # Lay so luong reviews\n",
    "            ET.SubElement(recipe_root, \"avgstar\", {\"average\": reviews_and_avgstars_tag[1].text.split()[0]}) # Lay so luong sao trung binh\n",
    "\n",
    "            # Lay loi trich dan\n",
    "            header_entry_content = article_tag.find_element(By.XPATH, './/div[@class=\"mb-6 entry-content italic\"]/p')\n",
    "            header_entry_content_tag = ET.SubElement(recipe_root, 'headdescription')\n",
    "            header_entry_content_tag.text = header_entry_content.text\n",
    "\n",
    "            # Lay cau truc cua bai viet\n",
    "            structure = ET.SubElement(recipe_root, 'structure')\n",
    "            entry_content = article_tag.find_element(By.XPATH, './/div[@class=\"entry-content\"]')\n",
    "            content_children = entry_content.find_elements(By.XPATH, './*')\n",
    "            slice_ = slice(1, len(content_children) - 2)\n",
    "            for child in content_children[slice_]:\n",
    "                if child.tag_name == 'figure':\n",
    "                    ET.SubElement(structure, 'image').text = child.find_element(By.TAG_NAME, 'img').get_attribute('src')\n",
    "                elif child.tag_name == 'h2' or child.tag_name == 'p':\n",
    "                    text_tag = ET.SubElement(structure, child.tag_name)\n",
    "                    text_tag.text = child.text\n",
    "                elif child.tag_name == 'ul' or child.tag_name == 'ol':\n",
    "                    list_tag = ET.SubElement(structure, child.tag_name)\n",
    "                    li_elements = child.find_elements(By.XPATH, './*')\n",
    "                    for li_element in li_elements:\n",
    "                        ET.SubElement(list_tag, 'li').text = li_element.text\n",
    "                elif child.tag_name == 'div':\n",
    "                    match child.get_attribute(\"class\"):\n",
    "                        case \"featured-comment disable-link-style\":\n",
    "                            ET.SubElement(structure, 'h5').text = child.find_element(By.XPATH, './/div[@class=\"featured-comment-content\"/h5]').text\n",
    "                            ET.SubElement(structure, 'p').text = child.find_element(By.XPATH, './/div[@class=\"featured-comment-content\"]/h5/div[@class=\"comment-text w-full\"]/p').text\n",
    "                            break\n",
    "                        case \"adthrive-video-player in-post\":\n",
    "                            ET.SubElement(structure, \"video\").text = child.find_element(By.XPATH, './/meta[@itemprop=\"contentUrl\"]').get_attribute(\"content\")\n",
    "                            break\n",
    "                        case \"wp-block-group lindsay-notes\":\n",
    "                            ET.SubElement(structure, \"h2\").text = child.find_element(By.TAG_NAME, 'h2').text\n",
    "                            p_tags = child.find_elements(By.TAG_NAME, 'p')\n",
    "                            p_text = \"\".join([p_tag.text for p_tag in p_tags])\n",
    "                            ET.SubElement(structure, 'p').text = p_text\n",
    "                            break\n",
    "                        case \"schema-faq wp-block-yoast-faq-block\":\n",
    "                            div_tags = child.find_elements(By.XPATH, \".//*\")\n",
    "                            questions = ET.SubElement(structure, \"questions\")\n",
    "                            for div_tag in div_tags:\n",
    "                                ET.SubElement(questions, \"strong\").text = div_tag.find_element(By.TAG_NAME, \"strong\").text\n",
    "                                ET.SubElement(questions, \"p\").text = div_tag.find_element(By.TAG_NAME, \"p\").text\n",
    "                            break\n",
    "                        case \"wp-block-group\":\n",
    "                            div_tags = child.find_elements(By.XPATH, './/div[@class=\"schema-faq wp-block-yoast-faq-block\"]/*')\n",
    "                            questions = ET.SubElement(structure, \"questions\")\n",
    "                            ET.SubElement(questions,'h2').text = child.find_element(By.TAG_NAME, \"h2\").text\n",
    "                            for div_tag in div_tags:\n",
    "                                ET.SubElement(questions, \"strong\").text = div_tag.find_element(By.TAG_NAME, \"strong\").text\n",
    "                                ET.SubElement(questions, \"p\").text = div_tag.find_element(By.TAG_NAME, \"p\").text\n",
    "                            break\n",
    "                        case \"wp-block-group recipe-step\":\n",
    "                            order_id = child.find_element(By.CLASS_NAME, \"wp-block-heading large-number\")\n",
    "                            step = ET.SubElement(structure, \"step\", order=order_id)\n",
    "                            ET.SubElement(step, \"h3\").text = child.find_element(By.XPATH, './/h3[@id=\"h-cook-the-noodles\"]').text\n",
    "                            ET.SubElement(step, 'p').text = child.find_element(By.TAG_NAME, 'p').text\n",
    "                            [ET.SubElement(step, 'image', url=img_tag.get_attribute('src')) for img_tag in child.find_elements(By.TAG_NAME, 'img')]\n",
    "                            break\n",
    "                        case _:\n",
    "                            ET.SubElement(structure, \"div\").text = child.text\n",
    "                            break\n",
    "\n",
    "\n",
    "            # Lay ngay viet bai\n",
    "            date = article_tag.find_elements(By.XPATH, './/div[@class=\"entry-footer\"]/div')\n",
    "            date = datetime.datetime.strptime(date[0].text, \"%B %d, %Y\")\n",
    "            ET.SubElement(recipe_root, 'createddate', date=date.date().isoformat())\n",
    "        \n",
    "            # Dong tab\n",
    "            driver.close()\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "            # Luu file xml\n",
    "            save_xml_file(recipe_root, f'./data/recipes/recipe_{count}.xml')\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            break\n",
    "\n",
    "        # Lay so luong trang\n",
    "        e = driver.find_elements(By.XPATH, '//div[@class=\"nav-links\"]')\n",
    "        num_pages = int(e[0].find_elements(By.TAG_NAME, 'a')[-2].text) \n",
    "\n",
    "        # Xu ly trang thu 2 tro di\n",
    "        # for i in tqdm.tqdm(range(2, num_pages + 1)):\n",
    "        #     driver.get(link + f'/page/{i}')\n",
    "            \n",
    "        break\n",
    "\n",
    "    break\n",
    "\n",
    "# save_xml_file(specified_types, './data/recipe_types/specified_types.xml')  \n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=chrome_options\n",
    ")\n",
    "# actions = ActionChains(driver)\n",
    "driver.get('https://pinchofyum.com/thai-peanut-chicken-bowls')\n",
    "article = driver.find_element(By.TAG_NAME, 'article')\n",
    "entry_content = article.find_element(By.XPATH, './/div[@class=\"entry-content\"]')\n",
    "\n",
    "article.find_element(By.XPATH, './/div[@class=\"entry-footer\"]/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
